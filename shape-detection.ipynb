{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yigit.sik\\Desktop\\ml\\shape-detection\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from skimage.filters import threshold_local\n",
    "from craft_hw_ocr import OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ShapeDetector:\n",
    "\tdef __init__(self):\n",
    "\t\tself.ocr_models = OCR.load_models()\n",
    "\t\tpass\n",
    "\n",
    "\tdef predict_shape(self, c):\n",
    "\t\t\n",
    "\t\tshape = None\n",
    "\t\tperi = cv2.arcLength(c, True)\n",
    "\t\tapprox = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "\t\t\n",
    "\t\tif len(approx) == 3:\n",
    "\t\t\tshape = \"triangle\"\n",
    "\t\telif len(approx) == 4:\n",
    "\t\t\t(x, y, w, h) = cv2.boundingRect(approx)\n",
    "\t\t\tar = w / float(h)\n",
    "\t\t\tshape = \"square\" if ar >= 0.95 and ar <= 1.05 else \"rectangle\"\n",
    "\t\telif len(approx) == 5:\n",
    "\t\t\tshape = \"pentagon\"\n",
    "\t\telif len(approx) > 5:\n",
    "\t\t\tshape = \"circle\"\n",
    "\t\n",
    "\t\treturn shape\n",
    "\t\n",
    "\tdef OCR(self, image):\n",
    "\n",
    "\t\timg_ocr, results = OCR.detection(image, self.ocr_models[2])\n",
    "\n",
    "\t\timg_text_cleared = img_ocr.copy()\n",
    "\n",
    "\t\tbboxes, texts = OCR.recoginition(img_ocr, results, self.ocr_models[0], self.ocr_models[1])\n",
    "\n",
    "\t\treturn bboxes, img_text_cleared, texts\n",
    "\n",
    "\tdef detect_shapes(self, image):\n",
    "\n",
    "\t\t# do the below step if your image is tilted by some angle else ignore\n",
    "\t\t# img = OCR.process_image(img)\n",
    "\t\tbboxes, img_text_cleared, texts = self.OCR(image)\n",
    "\t\timage_copy = image.copy()\n",
    "\t\t\n",
    "\t\tfor i in bboxes.astype('int32'):\n",
    "\t\t\tcv2.fillPoly(img_text_cleared, pts=[i], color=(0,0,0))\n",
    "\n",
    "\t\tresized = imutils.resize(img_text_cleared, width=100)\n",
    "\t\tratio = img_text_cleared.shape[0] / float(resized.shape[0])\n",
    "\t\t\n",
    "\t\tcnts = cv2.findContours(resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\tcnts = imutils.grab_contours(cnts)\n",
    "\n",
    "\t\timage_copy = cv2.cvtColor(image_copy,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "\t\tfor c in cnts:\n",
    "\n",
    "\t\t\tif cv2.contourArea(c) < 4:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\n",
    "\t\t\tperi = cv2.arcLength(c, True)\n",
    "\t\t\t#print(len(cv2.approxPolyDP(c, 0.04 * peri, True)))\n",
    "\t\t\t\n",
    "\t\t\tM = cv2.moments(c)\n",
    "\t\t\tif M[\"m00\"] > 0:\n",
    "\t\t\t\tcX = int((M[\"m10\"] / M[\"m00\"]) * ratio)\n",
    "\t\t\t\tcY = int((M[\"m01\"] / M[\"m00\"]) * ratio)\n",
    "\t\t\t\tshape = self.predict_shape(c)\n",
    "\t\t\t\tif shape == None : continue\n",
    "\t\t\t\tc = c.astype(\"float\")\n",
    "\t\t\t\tc *= ratio\n",
    "\t\t\t\tc = c.astype(\"int\")\n",
    "\n",
    "\t\t\t\tcv2.drawContours(image_copy, [c], -1, (255, 0, 0), 2)\n",
    "\t\t\t\tcv2.putText(image_copy, shape, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t\t0.5, (0, 0, 255), 2)\n",
    "\t\t\t\t\n",
    "\t\tfor i,j in enumerate(bboxes):\n",
    "\n",
    "\t\t\ty1 = int(bboxes[i][0][1])\n",
    "\t\t\ty2 = int(bboxes[i][2][1])\n",
    "\t\t\t\n",
    "\t\t\tx1 = int(bboxes[i][0][0])\n",
    "\t\t\tx2 = int(bboxes[i][2][0])\n",
    "\t\t\t\n",
    "\t\t\tcv2.rectangle(image_copy, (x1, y1), (x2, y2), (0,0,255), 2)\n",
    "\t\t\n",
    "\n",
    "\t\treturn image_copy, texts\n",
    "\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Preprocessing:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def shadow_remove(self, img):\n",
    "            rgb_planes = cv2.split(img)\n",
    "            result_norm_planes = []\n",
    "            for plane in rgb_planes:\n",
    "                dilated_img = cv2.dilate(plane, np.ones((17,17), np.uint8))\n",
    "                bg_img = cv2.medianBlur(dilated_img, 21)\n",
    "                diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
    "                norm_img = cv2.normalize(diff_img,None, alpha=40, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "                result_norm_planes.append(norm_img)\n",
    "            shadowremov = cv2.merge(result_norm_planes)\n",
    "            return shadowremov\n",
    "\n",
    "    def order_points(self,pts):\n",
    "    \n",
    "        rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "       \n",
    "        s = pts.sum(axis = 1) \n",
    "        rect[0] = pts[np.argmin(s)] \n",
    "        rect[2] = pts[np.argmax(s)] \n",
    "\n",
    "        diff = np.diff(pts, axis = 1)\n",
    "        rect[1] = pts[np.argmin(diff)] \n",
    "        rect[3] = pts[np.argmax(diff)] \n",
    "       \n",
    "        return rect\n",
    "    \n",
    "    def four_point_transform(self,image, pts):\n",
    "\n",
    "        rect = self.order_points(pts)\n",
    "        (tl, tr, br, bl) = rect \n",
    "\n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2)) \n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "        maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        maxHeight = max(int(heightA), int(heightB))\n",
    "       \n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [maxWidth - 1, 0],\n",
    "            [maxWidth - 1, maxHeight - 1],\n",
    "            [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(rect, dst)\n",
    "        warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    \n",
    "        return warped\n",
    "    \n",
    "    def scan_image(self, image):\n",
    "           \n",
    "        ratio = image.shape[0] / 500.0\n",
    "        orig = image.copy()\n",
    "        image = imutils.resize(image, height = 500)\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edged = cv2.Canny(gray, 100, 255)\n",
    "\n",
    "        cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "    \n",
    "\n",
    "        for c in cnts:\n",
    "            \n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "            \n",
    "            if len(approx) == 4:\n",
    "                screenCnt = approx\n",
    "                break\n",
    "\n",
    "        cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "\n",
    "        warped = self.four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "        warped = warped[20:-20,20:-20]\n",
    "\n",
    "        return warped\n",
    "\n",
    "    \n",
    "    def preprocess(self,image):\n",
    "\n",
    "        img_copy = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        img_erosion = cv2.erode(img_copy, kernel, iterations=3)\n",
    "        dilated = cv2.dilate(img_erosion, kernel, iterations=3)\n",
    "        \n",
    "        blur = cv2.GaussianBlur(dilated, (15,15), sigmaX=33, sigmaY=33)\n",
    "        divided = cv2.divide(dilated, blur, scale=255)\n",
    "\n",
    "        clahe = cv2.createCLAHE(clipLimit = 1)\n",
    "        final_img = clahe.apply(divided) + 30\n",
    "\n",
    "        final_img = cv2.bitwise_not(final_img) \n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        opening = cv2.morphologyEx(final_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        (thresh, im_bw) = cv2.threshold(opening, 20, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "        final_img = cv2.bitwise_not(im_bw)\n",
    "\n",
    "        return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "preprocessing = Preprocessing()\n",
    "shape_detector = ShapeDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_folder = \"./images/\"\n",
    "output_folder =\"./output/\"\n",
    "filenames = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
    "os.makedirs(os.path.dirname(output_folder), exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for file in filenames:\n",
    "  \n",
    "#     filepath = input_folder + file\n",
    "#     image = cv2.imread(filepath)\n",
    "\n",
    "#     img_shadow_removed = preprocessing.shadow_remove(image)\n",
    "#     img_scanned = preprocessing.scan_image(img_shadow_removed)\n",
    "#     img_preprocess = preprocessing.preprocess(img_scanned)\n",
    "#     img_shape_detected, texts = shape_detector.detect_shapes(img_preprocess)\n",
    "\n",
    "#     fig = plt.figure(figsize=(15, 20))\n",
    "\n",
    "#     figures = { \"Original\": image,\n",
    "#                 \"Shadow Removed\": img_shadow_removed,\n",
    "#                 \"Scanned\": img_scanned,\n",
    "#                 \"Shape Detection\": img_shape_detected\n",
    "#                 }\n",
    "\n",
    "#     for i,key in enumerate(figures):\n",
    "\n",
    "#         fig.add_subplot(2, 2, i+1)\n",
    "#         plt.imshow(figures[key])\n",
    "#         plt.axis('off')\n",
    "#         plt.title(key)\n",
    "\n",
    "    \n",
    "#     fig.savefig(output_folder + file.split('.')[0]+\"_figure.jpg\")\n",
    "#     cv2.imwrite(output_folder + file.split('.')[0]+\"_detected.jpg\",img_shape_detected)\n",
    "#     with open(output_folder + file.split('.')[0]+\".txt\", \"w\") as f:\n",
    "#         f.write(texts)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(\"./images/1.jpg\")\n",
    "\n",
    "# Remove shadow\n",
    "img_shadow_removed = preprocessing.shadow_remove(image)\n",
    "\n",
    "cv2.imshow(\"orjinal.jpg\",img_shadow_removed)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Remove background by scanning the image\n",
    "img_scanned = preprocessing.scan_image(img_shadow_removed)\n",
    "\n",
    "cv2.imshow(\"img_scanned.jpg\",img_scanned)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Convert image to grayscale\n",
    "img_copy = cv2.cvtColor(img_scanned.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"grayscale.jpg\",img_copy)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "kernelSizes = [(2, 2), (3, 3), (5, 5)]\n",
    "blur =[3,5,7]\n",
    "# loop over the kernels sizes\n",
    "for i, kernelSize in enumerate(kernelSizes):\n",
    "\n",
    "    \n",
    "    img_blur = cv2.medianBlur(img_copy, blur[i])\n",
    "    cv2.imshow(\"blur\",img_blur)\n",
    "    cv2.waitKey(10000)\n",
    "\n",
    "    \n",
    "    edged = cv2.Canny(img_blur, 30, 30)\n",
    "\n",
    "    cv2.imshow(\"edged.jpg\",edged)\n",
    "    cv2.waitKey(10000)\n",
    "\n",
    "    edged = cv2.bitwise_not(edged)\n",
    "\n",
    "\n",
    "    # Erosion - Dilation : Removes small blobs from image\n",
    "\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "\n",
    "    img_erosion = cv2.erode(edged, kernel, iterations=1)\n",
    "\n",
    "    cv2.imshow(\"erosion.jpg\",img_erosion)\n",
    "    cv2.waitKey()\n",
    "\n",
    "    dilated = cv2.dilate(img_erosion, kernel, iterations=1)\n",
    "\n",
    "    cv2.imshow(\"dilated.jpg\",dilated)\n",
    "    cv2.waitKey()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(\"./images/1.jpg\")\n",
    "\n",
    "# Remove shadow\n",
    "img_shadow_removed = preprocessing.shadow_remove(image)\n",
    "\n",
    "cv2.imshow(\"orjinal.jpg\",img_shadow_removed)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Remove background by scanning the image\n",
    "img_scanned = preprocessing.scan_image(img_shadow_removed)\n",
    "\n",
    "cv2.imshow(\"img_scanned.jpg\",img_scanned)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Convert image to grayscale\n",
    "img_copy = cv2.cvtColor(img_scanned.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"grayscale.jpg\",img_copy)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "kernelSizes = [(2, 2), (3, 3), (5, 5)]\n",
    "blur =[3,5,7]\n",
    "# loop over the kernels sizes\n",
    "for i, kernelSize in enumerate(kernelSizes):\n",
    "\n",
    "    \n",
    "    img_blur = cv2.medianBlur(img_copy, blur[i])\n",
    "    cv2.imshow(\"blur\",img_blur)\n",
    "    cv2.waitKey(10000)\n",
    "\n",
    "    \n",
    "    edged = cv2.Canny(img_blur, 30, 30)\n",
    "\n",
    "    cv2.imshow(\"edged.jpg\",edged)\n",
    "    cv2.waitKey(10000)\n",
    "\n",
    "    edged = cv2.bitwise_not(edged)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernelSize)\n",
    "    opening = cv2.morphologyEx(edged, cv2.MORPH_OPEN, kernel)\n",
    "    cv2.imshow(\"Opening: ({}, {})\".format(kernelSize[0], kernelSize[1]), opening)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernelSize)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imshow(\"Closing: ({}, {})\".format(kernelSize[0], kernelSize[1]), closing)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"./images/7.jpg\")\n",
    "\n",
    "# # Remove shadow\n",
    "# img_shadow_removed = preprocessing.shadow_remove(image)\n",
    "\n",
    "# cv2.imshow(\"orjinal.jpg\",img_shadow_removed)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# # Remove background by scanning the image\n",
    "# img_scanned = preprocessing.scan_image(img_shadow_removed)\n",
    "\n",
    "# cv2.imshow(\"img_scanned.jpg\",img_scanned)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# # Convert image to grayscale\n",
    "# img_copy = cv2.cvtColor(img_scanned.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# cv2.imshow(\"grayscale.jpg\",img_copy)\n",
    "# cv2.waitKey()\n",
    "\n",
    "\n",
    "# # Erosion - Dilation : Removes small blobs from image\n",
    "\n",
    "# kernel = np.ones((2,2), np.uint8)\n",
    "\n",
    "# img_erosion = cv2.erode(img_copy, kernel, iterations=3)\n",
    "\n",
    "# cv2.imshow(\"erosion.jpg\",img_erosion)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# dilated = cv2.dilate(img_erosion, kernel, iterations=3)\n",
    "\n",
    "# cv2.imshow(\"dilated.jpg\",dilated)\n",
    "# cv2.waitKey()\n",
    "\n",
    "\n",
    "# # Divide image with its blurred version to clean background\n",
    "\n",
    "# blur = cv2.GaussianBlur(dilated, (15,15), sigmaX=33, sigmaY=33)\n",
    "\n",
    "# cv2.imshow(\"blur.jpg\",blur)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# divided = cv2.divide(dilated, blur, scale=255)\n",
    "\n",
    "# cv2.imshow(\"divide.jpg\",divided)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# # Over-amplification of the contrast by Clache histogram equaization\n",
    "\n",
    "# clahe = cv2.createCLAHE(clipLimit = 1)\n",
    "# img_clahe = clahe.apply(divided) + 30\n",
    "\n",
    "# cv2.imshow(\"img_clahe.jpg\",img_clahe)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# # Morph Open cleans small blobs from the image\n",
    "\n",
    "# img_clahe = cv2.bitwise_not(img_clahe)\n",
    "\n",
    "# cv2.imshow(\"bitwise_not.jpg\",img_clahe)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "# opening = cv2.morphologyEx(img_clahe, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# cv2.imshow(\"MORPH_OPEN.jpg\",opening)\n",
    "# cv2.waitKey()\n",
    "\n",
    "\n",
    "# #Binarize image\n",
    "\n",
    "# (thresh, im_bw) = cv2.threshold(opening, 20, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "# # Findcountours expects white lines over black background\n",
    "\n",
    "# final_img = cv2.bitwise_not(im_bw)\n",
    "\n",
    "# cv2.imshow(\"final_img.jpg\",final_img)\n",
    "# cv2.waitKey()\n",
    "\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d17781ff5206a460652933fcfcb711bee22328c6d1feff486595ff35cd2272a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
